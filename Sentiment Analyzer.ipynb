{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c7e2d10",
   "metadata": {},
   "source": [
    "Anlyzing tweetz for some sucessful brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273e0b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: textblob in e:\\anaconda\\lib\\site-packages (0.18.0.post0)\n",
      "Requirement already satisfied: nltk>=3.8 in e:\\anaconda\\lib\\site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: click in e:\\anaconda\\lib\\site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in e:\\anaconda\\lib\\site-packages (from nltk>=3.8->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\anaconda\\lib\\site-packages (from nltk>=3.8->textblob) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in e:\\anaconda\\lib\\site-packages (from nltk>=3.8->textblob) (4.66.5)\n",
      "Requirement already satisfied: colorama in e:\\anaconda\\lib\\site-packages (from click->nltk>=3.8->textblob) (0.4.6)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6efc1bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in e:\\anaconda\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in e:\\anaconda\\lib\\site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\anaconda\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\anaconda\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\anaconda\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in e:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b450fd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the file specified.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy<2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40e0ded1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in e:\\anaconda\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: pyarrow in e:\\anaconda\\lib\\site-packages (18.1.0)\n",
      "Requirement already satisfied: textblob in e:\\anaconda\\lib\\site-packages (0.18.0.post0)\n",
      "Requirement already satisfied: matplotlib in e:\\anaconda\\lib\\site-packages (3.9.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in e:\\anaconda\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\anaconda\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\anaconda\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\anaconda\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: nltk>=3.8 in e:\\anaconda\\lib\\site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\anaconda\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\anaconda\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\anaconda\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in e:\\anaconda\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\anaconda\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in e:\\anaconda\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in e:\\anaconda\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: click in e:\\anaconda\\lib\\site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in e:\\anaconda\\lib\\site-packages (from nltk>=3.8->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\anaconda\\lib\\site-packages (from nltk>=3.8->textblob) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in e:\\anaconda\\lib\\site-packages (from nltk>=3.8->textblob) (4.66.5)\n",
      "Requirement already satisfied: six>=1.5 in e:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in e:\\anaconda\\lib\\site-packages (from click->nltk>=3.8->textblob) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pandas pyarrow textblob matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "488d894e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ForEach-Object' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "pip list --outdated | findstr -v Package | ForEach-Object {pip install --upgrade $_.split()[0]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c57c9087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in e:\\anaconda\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in e:\\anaconda\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\anaconda\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\anaconda\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\anaconda\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in e:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93647363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e706cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"e:\\Anaconda\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"e:\\Anaconda\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"e:\\Anaconda\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"e:\\Anaconda\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\goelk\\AppData\\Local\\Temp\\ipykernel_2840\\2654617989.py\", line 1, in <module>\n",
      "    import pandas as pd\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\pandas\\__init__.py\", line 62, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\pandas\\core\\api.py\", line 1, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\pandas\\_libs\\__init__.py\", line 17, in <module>\n",
      "    import pandas._libs.pandas_datetime  # noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.2 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.2 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtextblob\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextBlob\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\pandas\\__init__.py:62\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     ArrowDtype,\n\u001b[0;32m     52\u001b[0m     Int8Dtype,\n\u001b[0;32m     53\u001b[0m     Int16Dtype,\n\u001b[0;32m     54\u001b[0m     Int32Dtype,\n\u001b[0;32m     55\u001b[0m     Int64Dtype,\n\u001b[0;32m     56\u001b[0m     UInt8Dtype,\n\u001b[0;32m     57\u001b[0m     UInt16Dtype,\n\u001b[0;32m     58\u001b[0m     UInt32Dtype,\n\u001b[0;32m     59\u001b[0m     UInt64Dtype,\n\u001b[0;32m     60\u001b[0m     Float32Dtype,\n\u001b[0;32m     61\u001b[0m     Float64Dtype,\n\u001b[1;32m---> 62\u001b[0m     CategoricalDtype,\n\u001b[0;32m     63\u001b[0m     PeriodDtype,\n\u001b[0;32m     64\u001b[0m     IntervalDtype,\n\u001b[0;32m     65\u001b[0m     DatetimeTZDtype,\n\u001b[0;32m     66\u001b[0m     StringDtype,\n\u001b[0;32m     67\u001b[0m     BooleanDtype,\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     NA,\n\u001b[0;32m     70\u001b[0m     isna,\n\u001b[0;32m     71\u001b[0m     isnull,\n\u001b[0;32m     72\u001b[0m     notna,\n\u001b[0;32m     73\u001b[0m     notnull,\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     Index,\n\u001b[0;32m     76\u001b[0m     CategoricalIndex,\n\u001b[0;32m     77\u001b[0m     RangeIndex,\n\u001b[0;32m     78\u001b[0m     MultiIndex,\n\u001b[0;32m     79\u001b[0m     IntervalIndex,\n\u001b[0;32m     80\u001b[0m     TimedeltaIndex,\n\u001b[0;32m     81\u001b[0m     DatetimeIndex,\n\u001b[0;32m     82\u001b[0m     PeriodIndex,\n\u001b[0;32m     83\u001b[0m     IndexSlice,\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     NaT,\n\u001b[0;32m     86\u001b[0m     Period,\n\u001b[0;32m     87\u001b[0m     period_range,\n\u001b[0;32m     88\u001b[0m     Timedelta,\n\u001b[0;32m     89\u001b[0m     timedelta_range,\n\u001b[0;32m     90\u001b[0m     Timestamp,\n\u001b[0;32m     91\u001b[0m     date_range,\n\u001b[0;32m     92\u001b[0m     bdate_range,\n\u001b[0;32m     93\u001b[0m     Interval,\n\u001b[0;32m     94\u001b[0m     interval_range,\n\u001b[0;32m     95\u001b[0m     DateOffset,\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     to_numeric,\n\u001b[0;32m     98\u001b[0m     to_datetime,\n\u001b[0;32m     99\u001b[0m     to_timedelta,\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     Flags,\n\u001b[0;32m    102\u001b[0m     Grouper,\n\u001b[0;32m    103\u001b[0m     factorize,\n\u001b[0;32m    104\u001b[0m     unique,\n\u001b[0;32m    105\u001b[0m     value_counts,\n\u001b[0;32m    106\u001b[0m     NamedAgg,\n\u001b[0;32m    107\u001b[0m     array,\n\u001b[0;32m    108\u001b[0m     Categorical,\n\u001b[0;32m    109\u001b[0m     set_eng_float_format,\n\u001b[0;32m    110\u001b[0m     Series,\n\u001b[0;32m    111\u001b[0m     DataFrame,\n\u001b[0;32m    112\u001b[0m )\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\pandas\\core\\api.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     NaT,\n\u001b[0;32m      3\u001b[0m     Period,\n\u001b[0;32m      4\u001b[0m     Timedelta,\n\u001b[0;32m      5\u001b[0m     Timestamp,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     ArrowDtype,\n\u001b[0;32m     11\u001b[0m     CategoricalDtype,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     PeriodDtype,\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\pandas\\_libs\\__init__.py:17\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Below imports needs to happen first to ensure pandas top level\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# module gets monkeypatched with the pandas_datetime_CAPI\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# see pandas_datetime_exec in pd_datetime.c\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     NaT,\n\u001b[0;32m     21\u001b[0m     NaTType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     iNaT,\n\u001b[0;32m     27\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove special characters, URLs, and other unwanted elements\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'[^A-Za-z0-9]+', ' ', text)  # Remove special characters\n",
    "    return text.strip()\n",
    "\n",
    "def analyze_sentiment(tweets):\n",
    "    positive = 0\n",
    "    neutral = 0\n",
    "    negative = 0\n",
    "\n",
    "    for tweet in tweets:\n",
    "        cleaned_tweet = clean_text(tweet)\n",
    "        analysis = TextBlob(cleaned_tweet)\n",
    "        sentiment_score = analysis.sentiment.polarity\n",
    "\n",
    "        if sentiment_score > 0:\n",
    "            positive += 1\n",
    "        elif sentiment_score < 0:\n",
    "            negative += 1\n",
    "        else:\n",
    "            neutral += 1\n",
    "\n",
    "    total = len(tweets)\n",
    "    positive_percentage = (positive / total) * 100\n",
    "    neutral_percentage = (neutral / total) * 100\n",
    "    negative_percentage = (negative / total) * 100\n",
    "\n",
    "    return positive_percentage, neutral_percentage, negative_percentage\n",
    "\n",
    "def plot_pie_chart(positive, neutral, negative):\n",
    "    labels = 'Positive', 'Neutral', 'Negative'\n",
    "    sizes = [positive, neutral, negative]\n",
    "    colors = ['yellowgreen', 'lightskyblue', 'lightcoral']\n",
    "    explode = (0.1, 0, 0)  # explode 1st slice\n",
    "\n",
    "    plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
    "            autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "    plt.axis('equal')\n",
    "    plt.title('Sentiment Analysis Results')\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    file_path = 'phone_tweets.csv'\n",
    "    df = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "    user_query = input(\"Enter the word to search in tweets: \")\n",
    "\n",
    "    # Filter tweets containing the user-specified word\n",
    "    filtered_tweets = df[df['tweet'].str.contains(user_query, case=False)]['tweet'].tolist()\n",
    "\n",
    "    if not filtered_tweets:\n",
    "        print(f\"No tweets found containing the word '{user_query}'.\")\n",
    "    else:\n",
    "        print(\"Filtered Tweets:\")\n",
    "        for tweet in filtered_tweets:\n",
    "            print(\"-\", tweet)\n",
    "\n",
    "        positive, neutral, negative = analyze_sentiment(filtered_tweets)\n",
    "        print(f\"\\nPositive: {positive:.2f}%\")\n",
    "        print(f\"Neutral: {neutral:.2f}%\")\n",
    "        print(f\"Negative: {negative:.2f}%\")\n",
    "\n",
    "        plot_pie_chart(positive, neutral, negative)\n",
    "\n",
    "     \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03c571a",
   "metadata": {},
   "source": [
    "Extracting positive tweets of sucessfull brands for key factor analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3d1c581",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m             positive_tweets\u001b[38;5;241m.\u001b[39mappend(text)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m positive_tweets\n\u001b[1;32m---> 13\u001b[0m dataset \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphone_tweets.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Assuming your original dataset is already loaded into 'dataset' variable\u001b[39;00m\n\u001b[0;32m     15\u001b[0m positive_tweets \u001b[38;5;241m=\u001b[39m extract_positive_tweets(dataset)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_positive_tweets(dataset):\n",
    "    positive_tweets = []\n",
    "    \n",
    "    for index, row in dataset.iterrows():\n",
    "        text = row[\"tweet\"]\n",
    "        # Perform sentiment analysis using TextBlob\n",
    "        analysis = TextBlob(text)\n",
    "        # Consider tweets with a polarity score greater than 0.5 as positive\n",
    "        if analysis.sentiment.polarity > 0.5:\n",
    "            positive_tweets.append(text)\n",
    "    \n",
    "    return positive_tweets\n",
    "dataset = pd.read_csv(\"phone_tweets.csv\")\n",
    "# Assuming your original dataset is already loaded into 'dataset' variable\n",
    "positive_tweets = extract_positive_tweets(dataset)\n",
    "\n",
    "# Create a new dataset called 'usethis' with the positive tweets\n",
    "usethis = pd.DataFrame({\"tweet\": positive_tweets})\n",
    "\n",
    "# Save the new dataset to a CSV file\n",
    "usethis.to_csv(\"postive_allbrands.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07d3ae1",
   "metadata": {},
   "source": [
    "key factor extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68ebec02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"e:\\Anaconda\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"e:\\Anaconda\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"e:\\Anaconda\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"e:\\Anaconda\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\goelk\\AppData\\Local\\Temp\\ipykernel_2840\\3103975023.py\", line 1, in <module>\n",
      "    import pandas as pd\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\pandas\\__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\pandas\\core\\api.py\", line 1, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\pandas\\_libs\\__init__.py\", line 17, in <module>\n",
      "    import pandas._libs.pandas_datetime  # noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.2 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.2 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m word_tokenize\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\pandas\\__init__.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     ArrowDtype,\n\u001b[0;32m     52\u001b[0m     Int8Dtype,\n\u001b[0;32m     53\u001b[0m     Int16Dtype,\n\u001b[0;32m     54\u001b[0m     Int32Dtype,\n\u001b[0;32m     55\u001b[0m     Int64Dtype,\n\u001b[0;32m     56\u001b[0m     UInt8Dtype,\n\u001b[0;32m     57\u001b[0m     UInt16Dtype,\n\u001b[0;32m     58\u001b[0m     UInt32Dtype,\n\u001b[0;32m     59\u001b[0m     UInt64Dtype,\n\u001b[0;32m     60\u001b[0m     Float32Dtype,\n\u001b[0;32m     61\u001b[0m     Float64Dtype,\n\u001b[0;32m     62\u001b[0m     CategoricalDtype,\n\u001b[0;32m     63\u001b[0m     PeriodDtype,\n\u001b[0;32m     64\u001b[0m     IntervalDtype,\n\u001b[0;32m     65\u001b[0m     DatetimeTZDtype,\n\u001b[0;32m     66\u001b[0m     StringDtype,\n\u001b[0;32m     67\u001b[0m     BooleanDtype,\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     NA,\n\u001b[0;32m     70\u001b[0m     isna,\n\u001b[0;32m     71\u001b[0m     isnull,\n\u001b[0;32m     72\u001b[0m     notna,\n\u001b[0;32m     73\u001b[0m     notnull,\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     Index,\n\u001b[0;32m     76\u001b[0m     CategoricalIndex,\n\u001b[0;32m     77\u001b[0m     RangeIndex,\n\u001b[0;32m     78\u001b[0m     MultiIndex,\n\u001b[0;32m     79\u001b[0m     IntervalIndex,\n\u001b[0;32m     80\u001b[0m     TimedeltaIndex,\n\u001b[0;32m     81\u001b[0m     DatetimeIndex,\n\u001b[0;32m     82\u001b[0m     PeriodIndex,\n\u001b[0;32m     83\u001b[0m     IndexSlice,\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     NaT,\n\u001b[0;32m     86\u001b[0m     Period,\n\u001b[0;32m     87\u001b[0m     period_range,\n\u001b[0;32m     88\u001b[0m     Timedelta,\n\u001b[0;32m     89\u001b[0m     timedelta_range,\n\u001b[0;32m     90\u001b[0m     Timestamp,\n\u001b[0;32m     91\u001b[0m     date_range,\n\u001b[0;32m     92\u001b[0m     bdate_range,\n\u001b[0;32m     93\u001b[0m     Interval,\n\u001b[0;32m     94\u001b[0m     interval_range,\n\u001b[0;32m     95\u001b[0m     DateOffset,\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     to_numeric,\n\u001b[0;32m     98\u001b[0m     to_datetime,\n\u001b[0;32m     99\u001b[0m     to_timedelta,\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     Flags,\n\u001b[0;32m    102\u001b[0m     Grouper,\n\u001b[0;32m    103\u001b[0m     factorize,\n\u001b[0;32m    104\u001b[0m     unique,\n\u001b[0;32m    105\u001b[0m     value_counts,\n\u001b[0;32m    106\u001b[0m     NamedAgg,\n\u001b[0;32m    107\u001b[0m     array,\n\u001b[0;32m    108\u001b[0m     Categorical,\n\u001b[0;32m    109\u001b[0m     set_eng_float_format,\n\u001b[0;32m    110\u001b[0m     Series,\n\u001b[0;32m    111\u001b[0m     DataFrame,\n\u001b[0;32m    112\u001b[0m )\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\pandas\\core\\api.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     NaT,\n\u001b[0;32m      3\u001b[0m     Period,\n\u001b[0;32m      4\u001b[0m     Timedelta,\n\u001b[0;32m      5\u001b[0m     Timestamp,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     ArrowDtype,\n\u001b[0;32m     11\u001b[0m     CategoricalDtype,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     PeriodDtype,\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\pandas\\_libs\\__init__.py:17\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Below imports needs to happen first to ensure pandas top level\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# module gets monkeypatched with the pandas_datetime_CAPI\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# see pandas_datetime_exec in pd_datetime.c\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     NaT,\n\u001b[0;32m     21\u001b[0m     NaTType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     iNaT,\n\u001b[0;32m     27\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from collections import defaultdict\n",
    "import spacy\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load English language model for spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_keywords(text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word.lower() for word in tokens if word.isalnum() and word.lower() not in stop_words]\n",
    "    \n",
    "    # Calculate word frequency distribution\n",
    "    fdist = FreqDist(filtered_tokens)\n",
    "    \n",
    "    # Get the most common keywords\n",
    "    keywords = [word for word, freq in fdist.most_common(50)]  # Adjust the number as needed\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entities = [entity.text for entity in doc.ents if entity.label_ == \"ORG\" or entity.label_ == \"PRODUCT\"]\n",
    "    return entities\n",
    "\n",
    "def extract_positive_factors(tweets):\n",
    "    positive_factors = defaultdict(int)\n",
    "    \n",
    "    for tweet in tweets:\n",
    "        keywords = extract_keywords(tweet)\n",
    "        entities = extract_entities(tweet)\n",
    "        \n",
    "        for keyword in keywords:\n",
    "            positive_factors[keyword] += 1\n",
    "        \n",
    "        for entity in entities:\n",
    "            positive_factors[entity] += 1\n",
    "    \n",
    "    # Sort the positive factors by frequency\n",
    "    sorted_factors = sorted(positive_factors.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return sorted_factors\n",
    "\n",
    "# Load your dataset\n",
    "dataset = pd.read_csv(\"postive_allbrands.csv\")  # Adjust the filename and path as needed\n",
    "\n",
    "# Assuming your dataset has a column named \"text\" containing the tweets\n",
    "tweets = dataset[\"tweet\"].tolist()\n",
    "\n",
    "# Use the extract_positive_factors function defined earlier\n",
    "positive_factors_all = extract_positive_factors(tweets)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbf1322",
   "metadata": {},
   "source": [
    "Analysing the tweets of a particular brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60fb3be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"e:\\Anaconda\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"e:\\Anaconda\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"e:\\Anaconda\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"e:\\Anaconda\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\goelk\\AppData\\Local\\Temp\\ipykernel_2840\\3238700526.py\", line 1, in <module>\n",
      "    import pandas as pd\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\pandas\\__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\pandas\\core\\api.py\", line 1, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\pandas\\_libs\\__init__.py\", line 17, in <module>\n",
      "    import pandas._libs.pandas_datetime  # noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.2 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.2 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtextblob\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextBlob\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\pandas\\__init__.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     ArrowDtype,\n\u001b[0;32m     52\u001b[0m     Int8Dtype,\n\u001b[0;32m     53\u001b[0m     Int16Dtype,\n\u001b[0;32m     54\u001b[0m     Int32Dtype,\n\u001b[0;32m     55\u001b[0m     Int64Dtype,\n\u001b[0;32m     56\u001b[0m     UInt8Dtype,\n\u001b[0;32m     57\u001b[0m     UInt16Dtype,\n\u001b[0;32m     58\u001b[0m     UInt32Dtype,\n\u001b[0;32m     59\u001b[0m     UInt64Dtype,\n\u001b[0;32m     60\u001b[0m     Float32Dtype,\n\u001b[0;32m     61\u001b[0m     Float64Dtype,\n\u001b[0;32m     62\u001b[0m     CategoricalDtype,\n\u001b[0;32m     63\u001b[0m     PeriodDtype,\n\u001b[0;32m     64\u001b[0m     IntervalDtype,\n\u001b[0;32m     65\u001b[0m     DatetimeTZDtype,\n\u001b[0;32m     66\u001b[0m     StringDtype,\n\u001b[0;32m     67\u001b[0m     BooleanDtype,\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     NA,\n\u001b[0;32m     70\u001b[0m     isna,\n\u001b[0;32m     71\u001b[0m     isnull,\n\u001b[0;32m     72\u001b[0m     notna,\n\u001b[0;32m     73\u001b[0m     notnull,\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     Index,\n\u001b[0;32m     76\u001b[0m     CategoricalIndex,\n\u001b[0;32m     77\u001b[0m     RangeIndex,\n\u001b[0;32m     78\u001b[0m     MultiIndex,\n\u001b[0;32m     79\u001b[0m     IntervalIndex,\n\u001b[0;32m     80\u001b[0m     TimedeltaIndex,\n\u001b[0;32m     81\u001b[0m     DatetimeIndex,\n\u001b[0;32m     82\u001b[0m     PeriodIndex,\n\u001b[0;32m     83\u001b[0m     IndexSlice,\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     NaT,\n\u001b[0;32m     86\u001b[0m     Period,\n\u001b[0;32m     87\u001b[0m     period_range,\n\u001b[0;32m     88\u001b[0m     Timedelta,\n\u001b[0;32m     89\u001b[0m     timedelta_range,\n\u001b[0;32m     90\u001b[0m     Timestamp,\n\u001b[0;32m     91\u001b[0m     date_range,\n\u001b[0;32m     92\u001b[0m     bdate_range,\n\u001b[0;32m     93\u001b[0m     Interval,\n\u001b[0;32m     94\u001b[0m     interval_range,\n\u001b[0;32m     95\u001b[0m     DateOffset,\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     to_numeric,\n\u001b[0;32m     98\u001b[0m     to_datetime,\n\u001b[0;32m     99\u001b[0m     to_timedelta,\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     Flags,\n\u001b[0;32m    102\u001b[0m     Grouper,\n\u001b[0;32m    103\u001b[0m     factorize,\n\u001b[0;32m    104\u001b[0m     unique,\n\u001b[0;32m    105\u001b[0m     value_counts,\n\u001b[0;32m    106\u001b[0m     NamedAgg,\n\u001b[0;32m    107\u001b[0m     array,\n\u001b[0;32m    108\u001b[0m     Categorical,\n\u001b[0;32m    109\u001b[0m     set_eng_float_format,\n\u001b[0;32m    110\u001b[0m     Series,\n\u001b[0;32m    111\u001b[0m     DataFrame,\n\u001b[0;32m    112\u001b[0m )\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\pandas\\core\\api.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     NaT,\n\u001b[0;32m      3\u001b[0m     Period,\n\u001b[0;32m      4\u001b[0m     Timedelta,\n\u001b[0;32m      5\u001b[0m     Timestamp,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     ArrowDtype,\n\u001b[0;32m     11\u001b[0m     CategoricalDtype,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     PeriodDtype,\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\pandas\\_libs\\__init__.py:17\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Below imports needs to happen first to ensure pandas top level\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# module gets monkeypatched with the pandas_datetime_CAPI\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# see pandas_datetime_exec in pd_datetime.c\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     NaT,\n\u001b[0;32m     21\u001b[0m     NaTType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     iNaT,\n\u001b[0;32m     27\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove special characters, URLs, and other unwanted elements\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'[^A-Za-z0-9]+', ' ', text)  # Remove special characters\n",
    "    return text.strip()\n",
    "\n",
    "def analyze_sentiment(tweets):\n",
    "    positive = 0\n",
    "    neutral = 0\n",
    "    negative = 0\n",
    "\n",
    "    for tweet in tweets:\n",
    "        cleaned_tweet = clean_text(tweet)\n",
    "        analysis = TextBlob(cleaned_tweet)\n",
    "        sentiment_score = analysis.sentiment.polarity\n",
    "\n",
    "        if sentiment_score > 0:\n",
    "            positive += 1\n",
    "        elif sentiment_score < 0:\n",
    "            negative += 1\n",
    "        else:\n",
    "            neutral += 1\n",
    "\n",
    "    total = len(tweets)\n",
    "    positive_percentage = (positive / total) * 100\n",
    "    neutral_percentage = (neutral / total) * 100\n",
    "    negative_percentage = (negative / total) * 100\n",
    "\n",
    "    return positive_percentage, neutral_percentage, negative_percentage\n",
    "\n",
    "def plot_pie_chart(positive, neutral, negative):\n",
    "    labels = 'Positive', 'Neutral', 'Negative'\n",
    "    sizes = [positive, neutral, negative]\n",
    "    colors = ['yellowgreen', 'lightskyblue', 'lightcoral']\n",
    "    explode = (0.1, 0, 0)  # explode 1st slice\n",
    "\n",
    "    plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
    "            autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "    plt.axis('equal')\n",
    "    plt.title('Sentiment Analysis Results')\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    file_path = 'Apple-Twitter-Sentiment-DFE.csv'\n",
    "    df = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "    user_query = input(\"Enter the word to search in tweets: \")\n",
    "\n",
    "    # Filter tweets containing the user-specified word\n",
    "    filtered_tweets = df[df['text'].str.contains(user_query, case=False)]['text'].tolist()\n",
    "\n",
    "    if not filtered_tweets:\n",
    "        print(f\"No tweets found containing the word '{user_query}'.\")\n",
    "    else:\n",
    "        print(\"Filtered Tweets:\")\n",
    "        for tweet in filtered_tweets:\n",
    "            print(\"-\", tweet)\n",
    "\n",
    "        positive, neutral, negative = analyze_sentiment(filtered_tweets)\n",
    "        print(f\"\\nPositive: {positive:.2f}%\")\n",
    "        print(f\"Neutral: {neutral:.2f}%\")\n",
    "        print(f\"Negative: {negative:.2f}%\")\n",
    "\n",
    "        plot_pie_chart(positive, neutral, negative)\n",
    "\n",
    "     \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4499e7b",
   "metadata": {},
   "source": [
    "Extarcting positive tweets of the particular brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97fddaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: TextBlob in e:\\anaconda\\lib\\site-packages (0.18.0.post0)\n",
      "Requirement already satisfied: nltk>=3.8 in e:\\anaconda\\lib\\site-packages (from TextBlob) (3.9.1)\n",
      "Requirement already satisfied: click in e:\\anaconda\\lib\\site-packages (from nltk>=3.8->TextBlob) (8.1.7)\n",
      "Requirement already satisfied: joblib in e:\\anaconda\\lib\\site-packages (from nltk>=3.8->TextBlob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\anaconda\\lib\\site-packages (from nltk>=3.8->TextBlob) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in e:\\anaconda\\lib\\site-packages (from nltk>=3.8->TextBlob) (4.66.5)\n",
      "Requirement already satisfied: colorama in e:\\anaconda\\lib\\site-packages (from click->nltk>=3.8->TextBlob) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94e5ffa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"e:\\Anaconda\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"e:\\Anaconda\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"e:\\Anaconda\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"e:\\Anaconda\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\goelk\\AppData\\Local\\Temp\\ipykernel_2840\\4232375300.py\", line 1, in <module>\n",
      "    import pandas as pd\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\pandas\\__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\pandas\\core\\api.py\", line 1, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\pandas\\_libs\\__init__.py\", line 17, in <module>\n",
      "    import pandas._libs.pandas_datetime  # noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.2 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.2 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtextblob\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextBlob\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load your dataset\u001b[39;00m\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\pandas\\__init__.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     ArrowDtype,\n\u001b[0;32m     52\u001b[0m     Int8Dtype,\n\u001b[0;32m     53\u001b[0m     Int16Dtype,\n\u001b[0;32m     54\u001b[0m     Int32Dtype,\n\u001b[0;32m     55\u001b[0m     Int64Dtype,\n\u001b[0;32m     56\u001b[0m     UInt8Dtype,\n\u001b[0;32m     57\u001b[0m     UInt16Dtype,\n\u001b[0;32m     58\u001b[0m     UInt32Dtype,\n\u001b[0;32m     59\u001b[0m     UInt64Dtype,\n\u001b[0;32m     60\u001b[0m     Float32Dtype,\n\u001b[0;32m     61\u001b[0m     Float64Dtype,\n\u001b[0;32m     62\u001b[0m     CategoricalDtype,\n\u001b[0;32m     63\u001b[0m     PeriodDtype,\n\u001b[0;32m     64\u001b[0m     IntervalDtype,\n\u001b[0;32m     65\u001b[0m     DatetimeTZDtype,\n\u001b[0;32m     66\u001b[0m     StringDtype,\n\u001b[0;32m     67\u001b[0m     BooleanDtype,\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     NA,\n\u001b[0;32m     70\u001b[0m     isna,\n\u001b[0;32m     71\u001b[0m     isnull,\n\u001b[0;32m     72\u001b[0m     notna,\n\u001b[0;32m     73\u001b[0m     notnull,\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     Index,\n\u001b[0;32m     76\u001b[0m     CategoricalIndex,\n\u001b[0;32m     77\u001b[0m     RangeIndex,\n\u001b[0;32m     78\u001b[0m     MultiIndex,\n\u001b[0;32m     79\u001b[0m     IntervalIndex,\n\u001b[0;32m     80\u001b[0m     TimedeltaIndex,\n\u001b[0;32m     81\u001b[0m     DatetimeIndex,\n\u001b[0;32m     82\u001b[0m     PeriodIndex,\n\u001b[0;32m     83\u001b[0m     IndexSlice,\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     NaT,\n\u001b[0;32m     86\u001b[0m     Period,\n\u001b[0;32m     87\u001b[0m     period_range,\n\u001b[0;32m     88\u001b[0m     Timedelta,\n\u001b[0;32m     89\u001b[0m     timedelta_range,\n\u001b[0;32m     90\u001b[0m     Timestamp,\n\u001b[0;32m     91\u001b[0m     date_range,\n\u001b[0;32m     92\u001b[0m     bdate_range,\n\u001b[0;32m     93\u001b[0m     Interval,\n\u001b[0;32m     94\u001b[0m     interval_range,\n\u001b[0;32m     95\u001b[0m     DateOffset,\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     to_numeric,\n\u001b[0;32m     98\u001b[0m     to_datetime,\n\u001b[0;32m     99\u001b[0m     to_timedelta,\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     Flags,\n\u001b[0;32m    102\u001b[0m     Grouper,\n\u001b[0;32m    103\u001b[0m     factorize,\n\u001b[0;32m    104\u001b[0m     unique,\n\u001b[0;32m    105\u001b[0m     value_counts,\n\u001b[0;32m    106\u001b[0m     NamedAgg,\n\u001b[0;32m    107\u001b[0m     array,\n\u001b[0;32m    108\u001b[0m     Categorical,\n\u001b[0;32m    109\u001b[0m     set_eng_float_format,\n\u001b[0;32m    110\u001b[0m     Series,\n\u001b[0;32m    111\u001b[0m     DataFrame,\n\u001b[0;32m    112\u001b[0m )\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\pandas\\core\\api.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     NaT,\n\u001b[0;32m      3\u001b[0m     Period,\n\u001b[0;32m      4\u001b[0m     Timedelta,\n\u001b[0;32m      5\u001b[0m     Timestamp,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     ArrowDtype,\n\u001b[0;32m     11\u001b[0m     CategoricalDtype,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     PeriodDtype,\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\pandas\\_libs\\__init__.py:17\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Below imports needs to happen first to ensure pandas top level\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# module gets monkeypatched with the pandas_datetime_CAPI\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# see pandas_datetime_exec in pd_datetime.c\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     NaT,\n\u001b[0;32m     21\u001b[0m     NaTType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     iNaT,\n\u001b[0;32m     27\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Load your dataset\n",
    "def extract_positive_tweets(dataset):\n",
    "    positive_tweets = []\n",
    "    \n",
    "    for index, row in dataset.iterrows():\n",
    "        text = row[\"text\"]\n",
    "        # Perform sentiment analysis using TextBlob\n",
    "        analysis = TextBlob(text)\n",
    "        # Consider tweets with a polarity score greater than 0.5 as positive\n",
    "        if analysis.sentiment.polarity > 0.5:\n",
    "            positive_tweets.append(text)\n",
    "    \n",
    "    return positive_tweets\n",
    "dataset = pd.read_csv(\"Apple-Twitter-Sentiment-DFE.csv\",encoding=\"latin1\")\n",
    "# Assuming your original dataset is already loaded into 'dataset' variable\n",
    "positive_tweets = extract_positive_tweets(dataset)\n",
    "\n",
    "# Create a new dataset called 'usethis' with the positive tweets\n",
    "usethis = pd.DataFrame({\"tweet\": positive_tweets})\n",
    "\n",
    "# Save the new dataset to a CSV file\n",
    "usethis.to_csv(\"usethis.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61040d71",
   "metadata": {},
   "source": [
    "Key factors that the brand contain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc793e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.8.2-cp312-cp312-win_amd64.whl.metadata (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.11-cp312-cp312-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.10-cp312-cp312-win_amd64.whl.metadata (8.6 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.9-cp312-cp312-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.0 (from spacy)\n",
      "  Downloading thinc-8.3.2-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.4.8-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in e:\\anaconda\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in e:\\anaconda\\lib\\site-packages (from spacy) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in e:\\anaconda\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in e:\\anaconda\\lib\\site-packages (from spacy) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in e:\\anaconda\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in e:\\anaconda\\lib\\site-packages (from spacy) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\anaconda\\lib\\site-packages (from spacy) (24.1)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in e:\\anaconda\\lib\\site-packages (from spacy) (1.26.4)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in e:\\anaconda\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in e:\\anaconda\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in e:\\anaconda\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Collecting blis<1.1.0,>=1.0.0 (from thinc<8.4.0,>=8.3.0->spacy)\n",
      "  Downloading blis-1.0.1-cp312-cp312-win_amd64.whl.metadata (7.8 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.0->spacy)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.19.0 (from spacy)\n",
      "  Downloading numpy-2.0.2-cp312-cp312-win_amd64.whl.metadata (59 kB)\n",
      "Requirement already satisfied: colorama in e:\\anaconda\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in e:\\anaconda\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.20.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in e:\\anaconda\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\anaconda\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading marisa_trie-1.2.1-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Downloading spacy-3.8.2-cp312-cp312-win_amd64.whl (11.8 MB)\n",
      "   ---------------------------------------- 0.0/11.8 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.8/11.8 MB 9.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.9/11.8 MB 9.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.3/11.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.7/11.8 MB 10.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.3/11.8 MB 11.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.8/11.8 MB 10.2 MB/s eta 0:00:00\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.10-cp312-cp312-win_amd64.whl (39 kB)\n",
      "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading murmurhash-1.0.11-cp312-cp312-win_amd64.whl (25 kB)\n",
      "Downloading preshed-3.0.9-cp312-cp312-win_amd64.whl (122 kB)\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.4.8-cp312-cp312-win_amd64.whl (478 kB)\n",
      "Downloading thinc-8.3.2-cp312-cp312-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 10.8 MB/s eta 0:00:00\n",
      "Downloading numpy-2.0.2-cp312-cp312-win_amd64.whl (15.6 MB)\n",
      "   ---------------------------------------- 0.0/15.6 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 2.6/15.6 MB 13.8 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 5.2/15.6 MB 13.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 7.9/15.6 MB 12.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 10.5/15.6 MB 12.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.8/15.6 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.6 MB 12.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.6/15.6 MB 11.7 MB/s eta 0:00:00\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Downloading blis-1.0.1-cp312-cp312-win_amd64.whl (6.4 MB)\n",
      "   ---------------------------------------- 0.0/6.4 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 2.4/6.4 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.5/6.4 MB 12.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.4/6.4 MB 11.8 MB/s eta 0:00:00\n",
      "Downloading cloudpathlib-0.20.0-py3-none-any.whl (52 kB)\n",
      "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "   ---------------------------------------- 0.0/5.4 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 2.9/5.4 MB 12.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.2/5.4 MB 12.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.4/5.4 MB 10.9 MB/s eta 0:00:00\n",
      "Downloading marisa_trie-1.2.1-cp312-cp312-win_amd64.whl (150 kB)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, numpy, murmurhash, marisa-trie, cloudpathlib, catalogue, srsly, preshed, language-data, blis, langcodes, confection, weasel, thinc, spacy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "Successfully installed blis-1.0.1 catalogue-2.0.10 cloudpathlib-0.20.0 confection-0.1.5 cymem-2.0.10 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 murmurhash-1.0.11 numpy-2.0.2 preshed-3.0.9 spacy-3.8.2 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.3.2 wasabi-1.1.3 weasel-0.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'E:\\Anaconda\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.0.2 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.0.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c058d116",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "BLIS support requires blis: pip install blis",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprobability\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FreqDist\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defaultdict\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Download NLTK resources\u001b[39;00m\n\u001b[0;32m     10\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpunkt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\spacy\\__init__.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, Iterable, Union\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# set library-specific custom warning handling before doing anything else\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m setup_default_warnings\n\u001b[0;32m      8\u001b[0m setup_default_warnings()  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# These are imported as part of the API\u001b[39;00m\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\spacy\\errors.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Literal\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mErrorsWithCodes\u001b[39;00m(\u001b[38;5;28mtype\u001b[39m):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, code):\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\spacy\\compat.py:39\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatalogue\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _importlib_metadata \u001b[38;5;28;01mas\u001b[39;00m importlib_metadata  \u001b[38;5;66;03m# type: ignore[no-redef]    # noqa: F401\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optimizer  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     41\u001b[0m pickle \u001b[38;5;241m=\u001b[39m pickle\n\u001b[0;32m     42\u001b[0m copy_reg \u001b[38;5;241m=\u001b[39m copy_reg\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\thinc\\api.py:23\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config, ConfigValidationError, registry\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minitializers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     17\u001b[0m     configure_normal_init,\n\u001b[0;32m     18\u001b[0m     glorot_uniform_init,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     zero_init,\n\u001b[0;32m     22\u001b[0m )\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     24\u001b[0m     LSTM,\n\u001b[0;32m     25\u001b[0m     CauchySimilarity,\n\u001b[0;32m     26\u001b[0m     ClippedLinear,\n\u001b[0;32m     27\u001b[0m     Dish,\n\u001b[0;32m     28\u001b[0m     Dropout,\n\u001b[0;32m     29\u001b[0m     Embed,\n\u001b[0;32m     30\u001b[0m     Gelu,\n\u001b[0;32m     31\u001b[0m     HardSigmoid,\n\u001b[0;32m     32\u001b[0m     HardSwish,\n\u001b[0;32m     33\u001b[0m     HardSwishMobilenet,\n\u001b[0;32m     34\u001b[0m     HardTanh,\n\u001b[0;32m     35\u001b[0m     HashEmbed,\n\u001b[0;32m     36\u001b[0m     LayerNorm,\n\u001b[0;32m     37\u001b[0m     Linear,\n\u001b[0;32m     38\u001b[0m     Logistic,\n\u001b[0;32m     39\u001b[0m     Maxout,\n\u001b[0;32m     40\u001b[0m     Mish,\n\u001b[0;32m     41\u001b[0m     MultiSoftmax,\n\u001b[0;32m     42\u001b[0m     MXNetWrapper,\n\u001b[0;32m     43\u001b[0m     ParametricAttention,\n\u001b[0;32m     44\u001b[0m     ParametricAttention_v2,\n\u001b[0;32m     45\u001b[0m     PyTorchLSTM,\n\u001b[0;32m     46\u001b[0m     PyTorchRNNWrapper,\n\u001b[0;32m     47\u001b[0m     PyTorchWrapper,\n\u001b[0;32m     48\u001b[0m     PyTorchWrapper_v2,\n\u001b[0;32m     49\u001b[0m     PyTorchWrapper_v3,\n\u001b[0;32m     50\u001b[0m     Relu,\n\u001b[0;32m     51\u001b[0m     ReluK,\n\u001b[0;32m     52\u001b[0m     Sigmoid,\n\u001b[0;32m     53\u001b[0m     Softmax,\n\u001b[0;32m     54\u001b[0m     Softmax_v2,\n\u001b[0;32m     55\u001b[0m     SparseLinear,\n\u001b[0;32m     56\u001b[0m     SparseLinear_v2,\n\u001b[0;32m     57\u001b[0m     Swish,\n\u001b[0;32m     58\u001b[0m     TensorFlowWrapper,\n\u001b[0;32m     59\u001b[0m     TorchScriptWrapper_v1,\n\u001b[0;32m     60\u001b[0m     add,\n\u001b[0;32m     61\u001b[0m     array_getitem,\n\u001b[0;32m     62\u001b[0m     bidirectional,\n\u001b[0;32m     63\u001b[0m     chain,\n\u001b[0;32m     64\u001b[0m     clone,\n\u001b[0;32m     65\u001b[0m     concatenate,\n\u001b[0;32m     66\u001b[0m     expand_window,\n\u001b[0;32m     67\u001b[0m     keras_subclass,\n\u001b[0;32m     68\u001b[0m     list2array,\n\u001b[0;32m     69\u001b[0m     list2padded,\n\u001b[0;32m     70\u001b[0m     list2ragged,\n\u001b[0;32m     71\u001b[0m     map_list,\n\u001b[0;32m     72\u001b[0m     noop,\n\u001b[0;32m     73\u001b[0m     padded2list,\n\u001b[0;32m     74\u001b[0m     premap_ids,\n\u001b[0;32m     75\u001b[0m     pytorch_to_torchscript_wrapper,\n\u001b[0;32m     76\u001b[0m     ragged2list,\n\u001b[0;32m     77\u001b[0m     reduce_first,\n\u001b[0;32m     78\u001b[0m     reduce_last,\n\u001b[0;32m     79\u001b[0m     reduce_max,\n\u001b[0;32m     80\u001b[0m     reduce_mean,\n\u001b[0;32m     81\u001b[0m     reduce_sum,\n\u001b[0;32m     82\u001b[0m     remap_ids,\n\u001b[0;32m     83\u001b[0m     remap_ids_v2,\n\u001b[0;32m     84\u001b[0m     residual,\n\u001b[0;32m     85\u001b[0m     resizable,\n\u001b[0;32m     86\u001b[0m     siamese,\n\u001b[0;32m     87\u001b[0m     sigmoid_activation,\n\u001b[0;32m     88\u001b[0m     softmax_activation,\n\u001b[0;32m     89\u001b[0m     strings2arrays,\n\u001b[0;32m     90\u001b[0m     tuplify,\n\u001b[0;32m     91\u001b[0m     uniqued,\n\u001b[0;32m     92\u001b[0m     with_array,\n\u001b[0;32m     93\u001b[0m     with_array2d,\n\u001b[0;32m     94\u001b[0m     with_cpu,\n\u001b[0;32m     95\u001b[0m     with_debug,\n\u001b[0;32m     96\u001b[0m     with_flatten,\n\u001b[0;32m     97\u001b[0m     with_flatten_v2,\n\u001b[0;32m     98\u001b[0m     with_getitem,\n\u001b[0;32m     99\u001b[0m     with_list,\n\u001b[0;32m    100\u001b[0m     with_nvtx_range,\n\u001b[0;32m    101\u001b[0m     with_padded,\n\u001b[0;32m    102\u001b[0m     with_ragged,\n\u001b[0;32m    103\u001b[0m     with_reshape,\n\u001b[0;32m    104\u001b[0m     with_signpost_interval,\n\u001b[0;32m    105\u001b[0m )\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    107\u001b[0m     CategoricalCrossentropy,\n\u001b[0;32m    108\u001b[0m     CosineDistance,\n\u001b[0;32m    109\u001b[0m     L2Distance,\n\u001b[0;32m    110\u001b[0m     SequenceCategoricalCrossentropy,\n\u001b[0;32m    111\u001b[0m )\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    113\u001b[0m     Model,\n\u001b[0;32m    114\u001b[0m     change_attr_values,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    118\u001b[0m     wrap_model_recursive,\n\u001b[0;32m    119\u001b[0m )\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\thinc\\layers\\__init__.py:12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclipped_linear\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClippedLinear, HardSigmoid, HardTanh, ReluK\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclone\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconcatenate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m concatenate\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdish\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dish\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdropout\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dropout\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\thinc\\layers\\concatenate.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_width\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnoop\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m noop\n\u001b[1;32m---> 21\u001b[0m NUMPY_OPS \u001b[38;5;241m=\u001b[39m NumpyOps()\n\u001b[0;32m     24\u001b[0m InT \u001b[38;5;241m=\u001b[39m TypeVar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInT\u001b[39m\u001b[38;5;124m\"\u001b[39m, bound\u001b[38;5;241m=\u001b[39mAny)\n\u001b[0;32m     25\u001b[0m OutT \u001b[38;5;241m=\u001b[39m TypeVar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutT\u001b[39m\u001b[38;5;124m\"\u001b[39m, bound\u001b[38;5;241m=\u001b[39mUnion[Array2d, Sequence[Array2d], Ragged])\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\thinc\\backends\\numpy_ops.pyx:63\u001b[0m, in \u001b[0;36mthinc.backends.numpy_ops.NumpyOps.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: BLIS support requires blis: pip install blis"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from collections import defaultdict\n",
    "import spacy\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load English language model for spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_keywords(text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word.lower() for word in tokens if word.isalnum() and word.lower() not in stop_words]\n",
    "    \n",
    "    # Calculate word frequency distribution\n",
    "    fdist = FreqDist(filtered_tokens)\n",
    "    \n",
    "    # Get the most common keywords\n",
    "    keywords = [word for word, freq in fdist.most_common(50)]  # Adjust the number as needed\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entities = [entity.text for entity in doc.ents if entity.label_ == \"ORG\" or entity.label_ == \"PRODUCT\"]\n",
    "    return entities\n",
    "\n",
    "def extract_positive_factors(tweets):\n",
    "    positive_factors = defaultdict(int)\n",
    "    \n",
    "    for tweet in tweets:\n",
    "        keywords = extract_keywords(tweet)\n",
    "        entities = extract_entities(tweet)\n",
    "        \n",
    "        for keyword in keywords:\n",
    "            positive_factors[keyword] += 1\n",
    "        \n",
    "        for entity in entities:\n",
    "            positive_factors[entity] += 1\n",
    "    \n",
    "    # Sort the positive factors by frequency\n",
    "    sorted_factors = sorted(positive_factors.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return sorted_factors\n",
    "\n",
    "# Load your dataset\n",
    "dataset = pd.read_csv(\"usethis.csv\")  # Adjust the filename and path as needed\n",
    "\n",
    "# Assuming your dataset has a column named \"text\" containing the tweets\n",
    "tweets = dataset[\"tweet\"].tolist()\n",
    "\n",
    "# Use the extract_positive_factors function defined earlier\n",
    "positive_factors = extract_positive_factors(tweets)\n",
    "\n",
    "# Print the results\n",
    "print(\"Key positive factors:\")\n",
    "for factor, count in positive_factors:\n",
    "    print(f\"{factor}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df792ca",
   "metadata": {},
   "source": [
    "Extract key factors from positive tweets and store them in array for similarity calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9ae906",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ForwardRef._evaluate() missing 1 required keyword-only argument: 'recursive_guard'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprobability\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FreqDist\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defaultdict\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Download NLTK resources\u001b[39;00m\n\u001b[0;32m     12\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpunkt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\spacy\\__init__.py:13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# These are imported as part of the API\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config, prefer_gpu, require_cpu, require_gpu  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m util\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabout\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\spacy\\pipeline\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattributeruler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AttributeRuler\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdep_parser\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DependencyParser\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01medit_tree_lemmatizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EditTreeLemmatizer\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\spacy\\pipeline\\attributeruler.py:8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m util\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Errors\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Language\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmatcher\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Matcher\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscorer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Scorer\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\spacy\\language.py:46\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlang\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenizer_exceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BASE_EXCEPTIONS, URL_MATCH\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlookups\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_lookups\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipe_analysis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m analyze_pipes, print_pipe_analysis, validate_attrs\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschemas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     48\u001b[0m     ConfigSchema,\n\u001b[0;32m     49\u001b[0m     ConfigSchemaInit,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m     validate_init_settings,\n\u001b[0;32m     53\u001b[0m )\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscorer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Scorer\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\spacy\\pipe_analysis.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwasabi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m msg\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Errors\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokens\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Doc, Span, Token\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dot_to_dict\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# This lets us add type hints for mypy etc. without causing circular imports\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\spacy\\tokens\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_serialize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DocBin\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Doc\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmorphanalysis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MorphAnalysis\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\spacy\\tokens\\_serialize.py:14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Errors\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleFrozenList, ensure_path\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvocab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Vocab\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dict_proxies\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SpanGroups\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DOCBIN_ALL_ATTRS \u001b[38;5;28;01mas\u001b[39;00m ALL_ATTRS\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\spacy\\vocab.pyx:1\u001b[0m, in \u001b[0;36minit spacy.vocab\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\spacy\\tokens\\doc.pyx:49\u001b[0m, in \u001b[0;36minit spacy.tokens.doc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\spacy\\schemas.py:195\u001b[0m\n\u001b[0;32m    191\u001b[0m         obj \u001b[38;5;241m=\u001b[39m converted\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m validate(TokenPatternSchema, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpattern\u001b[39m\u001b[38;5;124m\"\u001b[39m: obj})\n\u001b[1;32m--> 195\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTokenPatternString\u001b[39;00m(BaseModel):\n\u001b[0;32m    196\u001b[0m     REGEX: Optional[Union[StrictStr, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenPatternString\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m Field(\u001b[38;5;28;01mNone\u001b[39;00m, alias\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    197\u001b[0m     IN: Optional[List[StrictStr]] \u001b[38;5;241m=\u001b[39m Field(\u001b[38;5;28;01mNone\u001b[39;00m, alias\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\pydantic\\v1\\main.py:286\u001b[0m, in \u001b[0;36mModelMetaclass.__new__\u001b[1;34m(mcs, name, bases, namespace, **kwargs)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__signature__ \u001b[38;5;241m=\u001b[39m ClassAttribute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__signature__\u001b[39m\u001b[38;5;124m'\u001b[39m, generate_model_signature(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m, fields, config))\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolve_forward_refs:\n\u001b[1;32m--> 286\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__try_update_forward_refs__()\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# preserve `__set_name__` protocol defined in https://peps.python.org/pep-0487\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# for attributes not in `new_namespace` (e.g. private attributes)\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, obj \u001b[38;5;129;01min\u001b[39;00m namespace\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\pydantic\\v1\\main.py:808\u001b[0m, in \u001b[0;36mBaseModel.__try_update_forward_refs__\u001b[1;34m(cls, **localns)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__try_update_forward_refs__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlocalns: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    804\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    805\u001b[0m \u001b[38;5;124;03m    Same as update_forward_refs but will not raise exception\u001b[39;00m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;124;03m    when forward references are not defined.\u001b[39;00m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 808\u001b[0m     update_model_forward_refs(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__fields__\u001b[38;5;241m.\u001b[39mvalues(), \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__config__\u001b[38;5;241m.\u001b[39mjson_encoders, localns, (\u001b[38;5;167;01mNameError\u001b[39;00m,))\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\pydantic\\v1\\typing.py:554\u001b[0m, in \u001b[0;36mupdate_model_forward_refs\u001b[1;34m(model, fields, json_encoders, localns, exc_to_suppress)\u001b[0m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fields:\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 554\u001b[0m         update_field_forward_refs(f, globalns\u001b[38;5;241m=\u001b[39mglobalns, localns\u001b[38;5;241m=\u001b[39mlocalns)\n\u001b[0;32m    555\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exc_to_suppress:\n\u001b[0;32m    556\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\pydantic\\v1\\typing.py:529\u001b[0m, in \u001b[0;36mupdate_field_forward_refs\u001b[1;34m(field, globalns, localns)\u001b[0m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m field\u001b[38;5;241m.\u001b[39msub_fields:\n\u001b[0;32m    528\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sub_f \u001b[38;5;129;01min\u001b[39;00m field\u001b[38;5;241m.\u001b[39msub_fields:\n\u001b[1;32m--> 529\u001b[0m         update_field_forward_refs(sub_f, globalns\u001b[38;5;241m=\u001b[39mglobalns, localns\u001b[38;5;241m=\u001b[39mlocalns)\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m field\u001b[38;5;241m.\u001b[39mdiscriminator_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    532\u001b[0m     field\u001b[38;5;241m.\u001b[39mprepare_discriminated_union_sub_fields()\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\pydantic\\v1\\typing.py:520\u001b[0m, in \u001b[0;36mupdate_field_forward_refs\u001b[1;34m(field, globalns, localns)\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m field\u001b[38;5;241m.\u001b[39mtype_\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;241m==\u001b[39m ForwardRef:\n\u001b[0;32m    519\u001b[0m     prepare \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 520\u001b[0m     field\u001b[38;5;241m.\u001b[39mtype_ \u001b[38;5;241m=\u001b[39m evaluate_forwardref(field\u001b[38;5;241m.\u001b[39mtype_, globalns, localns \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m field\u001b[38;5;241m.\u001b[39mouter_type_\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;241m==\u001b[39m ForwardRef:\n\u001b[0;32m    522\u001b[0m     prepare \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\pydantic\\v1\\typing.py:66\u001b[0m, in \u001b[0;36mevaluate_forwardref\u001b[1;34m(type_, globalns, localns)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_forwardref\u001b[39m(type_: ForwardRef, globalns: Any, localns: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Even though it is the right signature for python 3.9, mypy complains with\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# `error: Too many arguments for \"_evaluate\" of \"ForwardRef\"` hence the cast...\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Any, type_)\u001b[38;5;241m.\u001b[39m_evaluate(globalns, localns, \u001b[38;5;28mset\u001b[39m())\n",
      "\u001b[1;31mTypeError\u001b[0m: ForwardRef._evaluate() missing 1 required keyword-only argument: 'recursive_guard'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from collections import defaultdict\n",
    "import spacy\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load English language model for spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_keywords(text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word.lower() for word in tokens if word.isalnum() and word.lower() not in stop_words]\n",
    "    \n",
    "    # Calculate word frequency distribution\n",
    "    fdist = FreqDist(filtered_tokens)\n",
    "    \n",
    "    # Get the most common keywords\n",
    "    keywords = [word for word, freq in fdist.most_common(50)]  # Adjust the number as needed\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entities = [entity.text for entity in doc.ents if entity.label_ == \"ORG\" or entity.label_ == \"PRODUCT\"]\n",
    "    return entities\n",
    "\n",
    "def extract_positive_factors(tweets):\n",
    "    positive_factors = defaultdict(int)\n",
    "    \n",
    "    for tweet in tweets:\n",
    "        keywords = extract_keywords(tweet)\n",
    "        entities = extract_entities(tweet)\n",
    "        \n",
    "        for keyword in keywords:\n",
    "            positive_factors[keyword] += 1\n",
    "        \n",
    "        for entity in entities:\n",
    "            positive_factors[entity] += 1\n",
    "    \n",
    "    # Sort the positive factors by frequency\n",
    "    sorted_factors = sorted(positive_factors.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return sorted_factors\n",
    "\n",
    "# Load data from positive_allbrands.csv\n",
    "positive_allbrands_data = pd.read_csv(\"postive_allbrands.csv\")  # Adjust the filename and path as needed\n",
    "\n",
    "# Assuming your dataset has a column named \"text\" containing the tweets\n",
    "positive_allbrands_tweets = positive_allbrands_data[\"tweet\"].tolist()\n",
    "\n",
    "# Extract positive factors from positive_allbrands.csv\n",
    "positive_allbrands_factors = extract_positive_factors(positive_allbrands_tweets)\n",
    "\n",
    "# Convert positive factors to a dictionary\n",
    "positive_allbrands_dict = dict(positive_allbrands_factors)\n",
    "\n",
    "# Load data from usethis.csv\n",
    "usethis_data = pd.read_csv(\"usethis.csv\")  # Adjust the filename and path as needed\n",
    "\n",
    "# Assuming your dataset has a column named \"text\" containing the tweets\n",
    "usethis_tweets = usethis_data[\"tweet\"].tolist()\n",
    "\n",
    "# Extract positive factors from usethis.csv\n",
    "usethis_positive_factors = extract_positive_factors(usethis_tweets)\n",
    "\n",
    "# Convert positive factors to a dictionary\n",
    "usethis_positive_dict = dict(usethis_positive_factors)\n",
    "\n",
    "# Combine positive factors of all brands and tweets\n",
    "all_factors = list(positive_allbrands_dict.keys()) + list(usethis_positive_dict.keys())\n",
    "all_factors = list(set(all_factors))  # Remove duplicates\n",
    "\n",
    "# Create feature vectors for positive factors of all brands\n",
    "positive_allbrands_vector = [positive_allbrands_dict.get(factor, 0) for factor in all_factors]\n",
    "\n",
    "# Create feature vectors for positive factors of tweets in usethis.csv\n",
    "usethis_positive_vector = [usethis_positive_dict.get(factor, 0) for factor in all_factors]\n",
    "\n",
    "# Convert feature vectors to numpy arrays\n",
    "positive_allbrands_array = np.array([positive_allbrands_vector])\n",
    "usethis_positive_array = np.array([usethis_positive_vector])\n",
    "\n",
    "# Calculate cosine similarity between positive factors of all brands and tweets in usethis.csv\n",
    "cosine_similarity_scores = cosine_similarity(positive_allbrands_array, usethis_positive_array)\n",
    "\n",
    "# Print the cosine similarity scores\n",
    "print(\"Cosine Similarity Scores:\", cosine_similarity_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e880ad9",
   "metadata": {},
   "source": [
    "## Based on the similarity score predict the brand success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea4dbf4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cosine_similarity_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 19\u001b[0m\n\u001b[0;32m     13\u001b[0m thresholds \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhigh\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.8\u001b[39m,\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmoderate\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.4\u001b[39m\n\u001b[0;32m     16\u001b[0m }\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Use the similarity scores obtained earlier\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m similarity_scores \u001b[38;5;241m=\u001b[39m cosine_similarity_scores\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Predict success rates for the new brands\u001b[39;00m\n\u001b[0;32m     22\u001b[0m predicted_success_rates \u001b[38;5;241m=\u001b[39m predict_success_rate(similarity_scores, thresholds)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cosine_similarity_scores' is not defined"
     ]
    }
   ],
   "source": [
    "def predict_success_rate(similarity_scores, thresholds):\n",
    "    success_rates = []\n",
    "    for score in similarity_scores:\n",
    "        if score >= thresholds[\"high\"]:\n",
    "            success_rates.append(\"High\")\n",
    "        elif score >= thresholds[\"moderate\"]:\n",
    "            success_rates.append(\"Moderate\")\n",
    "        else:\n",
    "            success_rates.append(\"Low\")\n",
    "    return success_rates\n",
    "\n",
    "# Define thresholds for success rate categories\n",
    "thresholds = {\n",
    "    \"high\": 0.8,\n",
    "    \"moderate\": 0.4\n",
    "}\n",
    "\n",
    "# Use the similarity scores obtained earlier\n",
    "similarity_scores = cosine_similarity_scores\n",
    "\n",
    "# Predict success rates for the new brands\n",
    "predicted_success_rates = predict_success_rate(similarity_scores, thresholds)\n",
    "\n",
    "# Print the predicted success rates\n",
    "print(\"Predicted Success Rates:\", predicted_success_rates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6014ab33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in e:\\anaconda\\lib\\site-packages (1.9.4)\n",
      "Requirement already satisfied: numpy>=1.6.1 in e:\\anaconda\\lib\\site-packages (from wordcloud) (1.26.4)\n",
      "Requirement already satisfied: pillow in e:\\anaconda\\lib\\site-packages (from wordcloud) (10.4.0)\n",
      "Requirement already satisfied: matplotlib in e:\\anaconda\\lib\\site-packages (from wordcloud) (3.9.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\anaconda\\lib\\site-packages (from matplotlib->wordcloud) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\anaconda\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\anaconda\\lib\\site-packages (from matplotlib->wordcloud) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in e:\\anaconda\\lib\\site-packages (from matplotlib->wordcloud) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\anaconda\\lib\\site-packages (from matplotlib->wordcloud) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in e:\\anaconda\\lib\\site-packages (from matplotlib->wordcloud) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in e:\\anaconda\\lib\\site-packages (from matplotlib->wordcloud) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in e:\\anaconda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wordcloud Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43570bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in e:\\anaconda\\lib\\site-packages (1.9.4)\n",
      "Requirement already satisfied: numpy>=1.6.1 in e:\\anaconda\\lib\\site-packages (from wordcloud) (1.26.4)\n",
      "Requirement already satisfied: pillow in e:\\anaconda\\lib\\site-packages (from wordcloud) (10.4.0)\n",
      "Requirement already satisfied: matplotlib in e:\\anaconda\\lib\\site-packages (from wordcloud) (3.9.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\anaconda\\lib\\site-packages (from matplotlib->wordcloud) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\anaconda\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\anaconda\\lib\\site-packages (from matplotlib->wordcloud) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in e:\\anaconda\\lib\\site-packages (from matplotlib->wordcloud) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\anaconda\\lib\\site-packages (from matplotlib->wordcloud) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in e:\\anaconda\\lib\\site-packages (from matplotlib->wordcloud) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in e:\\anaconda\\lib\\site-packages (from matplotlib->wordcloud) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in e:\\anaconda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"e:\\Anaconda\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"e:\\Anaconda\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"e:\\Anaconda\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"e:\\Anaconda\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\goelk\\AppData\\Local\\Temp\\ipykernel_2840\\3312492103.py\", line 10, in <module>\n",
      "    import pandas as pd\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\pandas\\__init__.py\", line 62, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\pandas\\core\\api.py\", line 1, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"e:\\Anaconda\\Lib\\site-packages\\pandas\\_libs\\__init__.py\", line 17, in <module>\n",
      "    import pandas._libs.pandas_datetime  # noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.2 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.2 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#!/usr/bin/env python\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# coding: utf-8\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Import necessary libraries\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#Nisha tyagi\u001b[39;00m\n\u001b[0;32m      9\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install wordcloud Wordcloud\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\pandas\\__init__.py:62\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     ArrowDtype,\n\u001b[0;32m     52\u001b[0m     Int8Dtype,\n\u001b[0;32m     53\u001b[0m     Int16Dtype,\n\u001b[0;32m     54\u001b[0m     Int32Dtype,\n\u001b[0;32m     55\u001b[0m     Int64Dtype,\n\u001b[0;32m     56\u001b[0m     UInt8Dtype,\n\u001b[0;32m     57\u001b[0m     UInt16Dtype,\n\u001b[0;32m     58\u001b[0m     UInt32Dtype,\n\u001b[0;32m     59\u001b[0m     UInt64Dtype,\n\u001b[0;32m     60\u001b[0m     Float32Dtype,\n\u001b[0;32m     61\u001b[0m     Float64Dtype,\n\u001b[1;32m---> 62\u001b[0m     CategoricalDtype,\n\u001b[0;32m     63\u001b[0m     PeriodDtype,\n\u001b[0;32m     64\u001b[0m     IntervalDtype,\n\u001b[0;32m     65\u001b[0m     DatetimeTZDtype,\n\u001b[0;32m     66\u001b[0m     StringDtype,\n\u001b[0;32m     67\u001b[0m     BooleanDtype,\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     NA,\n\u001b[0;32m     70\u001b[0m     isna,\n\u001b[0;32m     71\u001b[0m     isnull,\n\u001b[0;32m     72\u001b[0m     notna,\n\u001b[0;32m     73\u001b[0m     notnull,\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     Index,\n\u001b[0;32m     76\u001b[0m     CategoricalIndex,\n\u001b[0;32m     77\u001b[0m     RangeIndex,\n\u001b[0;32m     78\u001b[0m     MultiIndex,\n\u001b[0;32m     79\u001b[0m     IntervalIndex,\n\u001b[0;32m     80\u001b[0m     TimedeltaIndex,\n\u001b[0;32m     81\u001b[0m     DatetimeIndex,\n\u001b[0;32m     82\u001b[0m     PeriodIndex,\n\u001b[0;32m     83\u001b[0m     IndexSlice,\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     NaT,\n\u001b[0;32m     86\u001b[0m     Period,\n\u001b[0;32m     87\u001b[0m     period_range,\n\u001b[0;32m     88\u001b[0m     Timedelta,\n\u001b[0;32m     89\u001b[0m     timedelta_range,\n\u001b[0;32m     90\u001b[0m     Timestamp,\n\u001b[0;32m     91\u001b[0m     date_range,\n\u001b[0;32m     92\u001b[0m     bdate_range,\n\u001b[0;32m     93\u001b[0m     Interval,\n\u001b[0;32m     94\u001b[0m     interval_range,\n\u001b[0;32m     95\u001b[0m     DateOffset,\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     to_numeric,\n\u001b[0;32m     98\u001b[0m     to_datetime,\n\u001b[0;32m     99\u001b[0m     to_timedelta,\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     Flags,\n\u001b[0;32m    102\u001b[0m     Grouper,\n\u001b[0;32m    103\u001b[0m     factorize,\n\u001b[0;32m    104\u001b[0m     unique,\n\u001b[0;32m    105\u001b[0m     value_counts,\n\u001b[0;32m    106\u001b[0m     NamedAgg,\n\u001b[0;32m    107\u001b[0m     array,\n\u001b[0;32m    108\u001b[0m     Categorical,\n\u001b[0;32m    109\u001b[0m     set_eng_float_format,\n\u001b[0;32m    110\u001b[0m     Series,\n\u001b[0;32m    111\u001b[0m     DataFrame,\n\u001b[0;32m    112\u001b[0m )\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\pandas\\core\\api.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     NaT,\n\u001b[0;32m      3\u001b[0m     Period,\n\u001b[0;32m      4\u001b[0m     Timedelta,\n\u001b[0;32m      5\u001b[0m     Timestamp,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     ArrowDtype,\n\u001b[0;32m     11\u001b[0m     CategoricalDtype,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     PeriodDtype,\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32me:\\Anaconda\\Lib\\site-packages\\pandas\\_libs\\__init__.py:17\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Below imports needs to happen first to ensure pandas top level\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# module gets monkeypatched with the pandas_datetime_CAPI\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# see pandas_datetime_exec in pd_datetime.c\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     NaT,\n\u001b[0;32m     21\u001b[0m     NaTType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     iNaT,\n\u001b[0;32m     27\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "# Import necessary libraries\n",
    "#Nisha tyagi\n",
    "get_ipython().system('pip install wordcloud Wordcloud')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "# Load the data\n",
    "\n",
    "data = pd.read_csv('instagram_data.csv', encoding='ISO-8859-1')\n",
    "df = pd.DataFrame(data)\n",
    "df\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "# Check for missing values\n",
    "data.isnull().sum()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "data.info()\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "# Plot distribution of Impressions from different sources\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.title(\"Distribution of Impressions From Home\")\n",
    "sns.distplot(data['From Home'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title(\"Distribution of Impressions From Hashtags\")\n",
    "sns.distplot(data['From Hashtags'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title(\"Distribution of Impressions From Explore\")\n",
    "sns.distplot(data['From Explore'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "# Plot pie chart for Impressions from different sources using Plotly\n",
    "home = data[\"From Home\"].sum()\n",
    "hashtags = data[\"From Hashtags\"].sum()\n",
    "explore = data[\"From Explore\"].sum()\n",
    "other = data[\"From Other\"].sum()\n",
    "\n",
    "labels = ['From Home', 'From Hashtags', 'From Explore', 'Other']\n",
    "values = [home, hashtags, explore, other]\n",
    "\n",
    "fig = px.pie(data, values=values, names=labels, title=\"Impressions on Instagram Posts From Various Sources\",hole=0.5)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "# Generate and plot word cloud for captions and hashtags\n",
    "text = \" \".join(i for i in data.Caption)\n",
    "stopwords = set(STOPWORDS)\n",
    "wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text)\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "text_hashtags = \" \".join(i for i in data.Hashtags)\n",
    "stopwords_hashtags = set(STOPWORDS)\n",
    "wordcloud_hashtags = WordCloud(stopwords=stopwords_hashtags, background_color=\"white\").generate(text_hashtags)\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.imshow(wordcloud_hashtags, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "# Scatter plots for relationships between variables using Plotly Express\n",
    "fig = px.scatter(data_frame=data, x=\"Impressions\", y=\"Likes\", size=\"Likes\", trendline=\"ols\", title=\"Relationship Between Likes and Total Impressions\")\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "fig = px.scatter(data_frame=data, x=\"Impressions\", y=\"Comments\", size=\"Comments\", trendline=\"ols\", title=\"Relationship Between Comments and Total Impressions\")\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "fig = px.scatter(data_frame=data, x=\"Impressions\", y=\"Shares\", size=\"Shares\", trendline=\"ols\", title=\"Relationship Between Shares and Total Impressions\")\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "\n",
    "fig = px.scatter(data_frame=data, x=\"Impressions\", y=\"Saves\", size=\"Saves\", trendline=\"ols\", title=\"Relationship Between Post Saves and Total Impressions\")\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "# Calculate and print correlation values for different variables\n",
    "correlation = data.corr()\n",
    "print(correlation[\"Impressions\"].sort_values(ascending=False))\n",
    "\n",
    "\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "\n",
    "# Calculate and print conversion rate\n",
    "conversion_rate = (data[\"Follows\"].sum() / data[\"Profile Visits\"].sum()) * 100\n",
    "print(conversion_rate)\n",
    "\n",
    "\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "\n",
    "# Scatter plot for relationship between Profile Visits and Followers Gained\n",
    "fig = px.scatter(data_frame=data, x=\"Profile Visits\", y=\"Follows\", size=\"Follows\", trendline=\"ols\", title=\"Relationship Between Profile Visits and Followers Gained\")\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "\n",
    "# Train a PassiveAggressiveRegressor model\n",
    "x = np.array(data[['Likes', 'Saves', 'Comments', 'Shares', 'Profile Visits', 'Follows']])\n",
    "y = np.array(data[\"Impressions\"])\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = PassiveAggressiveRegressor()\n",
    "model.fit(xtrain, ytrain)\n",
    "score = model.score(xtest, ytest)\n",
    "print(score)\n",
    "\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "\n",
    "# Predict with the trained model\n",
    "features = np.array([[282.0, 233.0, 4.0, 9.0, 165.0, 54.0]])\n",
    "prediction = model.predict(features)\n",
    "print(prediction)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c375b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
